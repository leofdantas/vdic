% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/06_siglip_embeddings.R
\name{.encode_text_siglip}
\alias{.encode_text_siglip}
\title{Encode text strings using SigLIP text encoder (internal)}
\usage{
.encode_text_siglip(
  text_strings,
  model = NULL,
  model_name = "google/siglip-so400m-patch14-384",
  normalize = TRUE,
  batch_size = 64L
)
}
\arguments{
\item{text_strings}{Character vector of words or phrases to encode}

\item{model}{Named list from [.load_siglip_model()]. If NULL (default), loads
the model automatically using the default model name.}

\item{model_name}{SigLIP model ID (default: "google/siglip-so400m-patch14-384").
Only used when model = NULL.}

\item{normalize}{Logical. If TRUE (default), normalizes each embedding to unit
length (L2 norm = 1). SigLIP embeddings are designed to be unit-normalized;
this ensures projections are cosine-similarity-based.}

\item{batch_size}{Integer. Number of strings to encode per batch (default: 64).
Larger batches are faster but use more memory.}
}
\value{
Numeric matrix of shape (length(text_strings) x 512). Row names are
  set to text_strings.
}
\description{
Encodes a character vector of text strings (typically dictionary words or
short phrases) into 512-dimensional vectors using the SigLIP text encoder.
The resulting vectors live in the shared text-image embedding space, which
means they can be used to build axes that score images.

Requires Python with the transformers, torch, and Pillow libraries.
See [vectionary_builder()] for setup instructions.
}
\keyword{internal}
