% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/04_vectionary.R
\name{.tokenize}
\alias{.tokenize}
\title{Tokenize text}
\usage{
.tokenize(text)
}
\arguments{
\item{text}{Character string to tokenize}
}
\value{
Character vector of lowercase tokens
}
\description{
Tokenizes text by splitting on whitespace and converting to lowercase.
}
\keyword{internal}
