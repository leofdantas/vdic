% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/04_vectionary.R
\name{vectionary_analyze}
\alias{vectionary_analyze}
\title{Analyze text with a vectionary}
\usage{
vectionary_analyze(vect, text, metric = "mean", alpha = NULL)
}
\arguments{
\item{vect}{A vectionary object built with [vectionary_builder()] or loaded
via [readRDS()].}

\item{text}{Character string or character vector of documents to analyze.}

\item{metric}{Which aggregation metric to calculate (default: "mean"):
\itemize{
  \item \code{"mean"}: Arithmetic mean of word projections — general-purpose summary
  \item \code{"mse"}: Root mean square — emphasizes high-magnitude projections
  \item \code{"sd"}: Standard deviation — spread of projections within the document
  \item \code{"se"}: Standard error of the mean — precision of the mean estimate
  \item \code{"top_10"}: Mean of the 10 highest projections — strongest signals only
  \item \code{"top_20"}: Mean of the 20 highest projections — strongest signals only
  \item \code{"all"}: Returns a list with all six metrics at once
}}

\item{alpha}{Significance level for one-tailed topic classification (e.g. 0.05).
When set, appends logical `_topic` columns to the result. The test computes
the mean projection per document and flags those exceeding
\eqn{\bar{x} + t_{1-\alpha,\, n-1} \cdot s}, where \eqn{\bar{x}} and
\eqn{s} are the corpus mean and SD of document-level means. Requires
\code{length(text) >= 2}. Default \code{NULL} (no test).}
}
\value{
A named list with one element per dimension. Each element is a
  numeric scalar (single document) or numeric vector (multiple documents).
  When \code{metric = "all"}, returns a list of such lists (one per metric).
  When \code{alpha} is set, the result also contains logical
  \code{_topic} elements and a \code{"threshold"} attribute with the
  per-dimension cutoffs. Convert to a data frame with
  \code{as.data.frame(result)}.
}
\description{
Analyzes one or more documents and returns scores per dimension.
Optionally applies a one-tailed t-test to classify documents as
matching each topic dimension.
}
\examples{
\dontrun{
my_vect <- readRDS("my_vectionary.rds")

# Single document
vectionary_analyze(my_vect, "We must protect vulnerable people", metric = "mse")

# Multiple documents
texts <- c(
  "We must protect vulnerable people",
  "Justice and equality for all citizens",
  "Loyal members stand together"
)
vectionary_analyze(my_vect, texts, metric = "mean")

# Topic classification (one-tailed t-test, alpha = 0.05)
vectionary_analyze(my_vect, texts, metric = "mean", alpha = 0.05)
}

}
